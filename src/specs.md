Team Activity Recognition Using Kinect Depth Map and Optical Images
 Understanding of Group Activities (GA) involving humans and objects have significant applications in civilian and military domains. The process of understanding GA is typically involved with spatiotemporal analysis of multi-modality sensor data. Video imagery is one popular sensing modality that offers rich data. However, making sense out of video imagery is a real challenge. In this research work, we would demonstrate applications of optical and Kinect imagery data for characterization of indoor group activities. Technical details of imagery techniques implemented for detection, tracking, and characterization of atomic events will also be investigated.

Activities Scenario:
Objects exchange – cooperation activity
Objects unloading – coordination activity
Object placing and picking – correlation activity
Unattended objects



<Data ref = “source”>  month/day/year, hr:min:sec, message-id, GPS coordinate, Cam pan angle: tilt angle, Space, local_space,  [Detection_focus: Attribute-1, Attribute-2, Attribute-3, Attribute-4, Attribute-5], Entity_Id, Group_Id, Confidence <Data ref = “source”>


[Human: cloth_color, posture, motion_type, human_interactions, role]

[Object: color, size, shape, state, H-ID]

[GA: type, people_count, object_count, group_formation, group_state]


Detection focus: Human

Color:

Posture:  standing, bending, sitting, laying down

Motion: stationary, walking, running, crawling, jumping

Interaction: shaking hands, waving hands, hugging

Role: Leader, subordinate, by-stander, unknown


Detection focus: Object

Color:

Size:  small, medium, large

Shape: square, rectangle, unknown

State: shaking hands, waving hands, hugging, none

H-ID: 


Detection focus: Group Activity

Type: Cooperation activities, correlation activities, coordination activities, object left behind

People count:  

Object count: 

Group formation: merging, talking, departing 

Group state: standing, talking, walking, sitting
